
# âš¡ Energy Consumption Metering (Time-Series)

### ğŸ“˜ Overview
**Energy Consumption Metering** is an **end-to-end batch data pipeline** built on **AWS**, designed to process smart electricity meter readings for **billing insights**, **anomaly detection**, and **interactive analytics**.  
The pipeline automatically ingests raw energy data, performs nightly ETL on **Databricks**, stores processed results in **Amazon S3**, and delivers them to **Athena**, **QuickSight**, and **API Gateway** for querying and visualization.

It provides:
1. **Automated Billing Reports** â€” daily and monthly consumption summaries.  
2. **Anomaly Detection Alerts** â€” near-real-time monitoring via SNS.  
3. **Interactive Dashboards** â€” visual analytics in QuickSight and Athena.

---

## ğŸ—ï¸ Solution Architecture
```
Smart Meter CSV (Readings)
â”‚
â–¼
Amazon S3 (Raw Zone)
â”‚
â–¼
Databricks ETL (Nightly Batch)
â”‚
â–¼
Amazon S3 (Processed Zone)
â”‚
â”œâ”€â”€â–¶ AWS Lambda â†’ Amazon SNS (Anomaly Alerts)
â”œâ”€â”€â–¶ AWS Lambda â†’ API Gateway (REST API for Billing)
â””â”€â”€â–¶ Amazon Athena â†’ QuickSight (Dashboards)

```
---

## âš™ï¸ Technologies Used

| Category | Technologies |
|-----------|--------------|
| **Data Ingestion** | Amazon S3 |
| **Data Processing** | Databricks, PySpark, Pandas |
| **Data Storage** | Amazon S3 (Raw + Processed zones) |
| **Query & Visualization** | Amazon Athena, Amazon QuickSight |
| **Automation & APIs** | AWS Lambda, API Gateway, Amazon SNS |
| **Languages / Libraries** | Python, Boto3, Pandas, PySpark, SQL |

---

## ğŸ”„ Pipeline Breakdown

### ğŸ”¹ Step 1: Data Ingestion
Raw electricity readings are uploaded as CSV files into an **S3 raw zone**:
`s3://electricity-meter-readings/raw/Readings.csv`

Each record represents minute-level measurements of voltage, current, and sub-metering data from household meters.

---

### ğŸ”¹ Step 2: ETL with Databricks (Batch Processing)

A **Databricks notebook (Nightly-ETL-Process)** performs:
1. **Extract:** Reads raw CSV files from S3.  
2. **Transform:** Cleans missing values, converts data types, and aggregates readings to daily level.  
3. **Load:** Writes final aggregated and billing-ready data to the processed S3 bucket:
`s3://electricity-meter-aggregated-readings/data/`


**Key Transformations:**
- Daily mean of power and voltage.
- Min/Max voltage per day.
- Sub-meter energy totals.
- Peak/Off-Peak billing (â‚¹8.5 and â‚¹5.0 rates).
- 3-sigma anomaly detection for abnormal energy use.

---

### ğŸ”¹ Step 3: Automated Billing via REST API

A **Lambda function** provides monthly billing summaries via **API Gateway**:

```bash
GET https://<api-id>[.execute-api.ap-south-1.amazonaws.com/bills?month=2007-04](https://.execute-api.ap-south-1.amazonaws.com/bills?month=2007-04)
````

**Lambda Logic:**

1.  Reads the latest billing CSV from S3.
2.  Filters by month (YYYY-MM).
3.  Returns JSON-formatted daily billing data.

### ğŸ”¹ Step 4: Anomaly Detection & Alerts (Rule-Based)

A second Lambda function runs after ETL to scan for anomalies and send alerts via **SNS**.

**Rules:**

  - ğŸ”º High consumption (\>150% of average)
  - âš ï¸ Zero consumption
  - âš¡ Sub-meter spikes (\>10,000 Wh)

**Alert Flow:**
S3 (Processed) â†’ Lambda â†’ SNS â†’ Email/SMS Subscribers

### ğŸ”¹ Step 5: Analytical Query Layer (Athena)

Processed data stored in S3 is queried directly using **Amazon Athena**.

**Athena Table Example:**

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS energy_bills.daily_summary (
    date STRING,
    avg_Global_active_power DOUBLE,
    avg_Voltage DOUBLE,
    total_Sub_metering_1 DOUBLE,
    total_Sub_metering_2 DOUBLE,
    total_Sub_metering_3 DOUBLE,
    total_daily_sum DOUBLE,
    anomaly_flag BOOLEAN,
    peak_charge DOUBLE,
    offpeak_charge DOUBLE,
    total_charge DOUBLE
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
LOCATION 's3://electricity-meter-aggregated-readings/data/'
TBLPROPERTIES ('skip.header.line.count'='1');
```

### ğŸ”¹ Step 6: Visualization with QuickSight

**QuickSight** connects directly to Athena.

**Dashboards visualize:**

  - Daily & Monthly consumption.
  - Voltage and intensity trends.
  - Billing comparisons across months.
  - Highlighted anomalies and alerts.

-----

## ğŸ§  Key Features
 
âœ… Automated nightly ETL using Databricks   
âœ… Peak and Off-Peak billing logic   
âœ… 3-Sigma anomaly detection   
âœ… Serverless REST API for on-demand bills   
âœ… SNS alert notifications for anomalies  
âœ… Queryable and visual insights via Athena & QuickSight   
âœ… Data partitioning for optimized cost & query performance   

-----

## âš”ï¸ Challenges & Solutions

| Challenge | Solution |
|-----------|----------|
| Large CSV file (200K+ rows) caused memory spikes | Streamed ingestion and Pandas chunk processing |
| Athena schema mismatch (string vs numeric) | Created clean folder with casted DOUBLE types |
| Frequent false positives in anomaly detection | Implemented statistical 3-sigma threshold and rule-based filters |
| Duplicate uploads overwriting old data | Timestamped ETL outputs (`billing_agg_YYYY-MM-DD_HH-MM-SS.csv`) |

-----

## ğŸ“‚ Project Structure

```
Energy-Consumption-Metering/
â”‚
â”œâ”€â”€ Nightly-ETL-Process.py      # Databricks ETL notebook
â”œâ”€â”€ billing_api_lambda.py       # REST API Lambda function
â”œâ”€â”€ anomaly_alert_lambda.py     # SNS alerting Lambda
â”œâ”€â”€ readings.csv                # Sample raw dataset
â”œâ”€â”€ architecture_diagram.png    # Pipeline visualization
â””â”€â”€ README.md
```

-----

## ğŸ“Š Sample Athena Query

```sql
SELECT 
  TRY_CAST(date AS DATE) AS consumption_date,
  avg_Global_active_power,
  total_daily_sum,
  peak_charge,
  offpeak_charge,
  total_charge
FROM energy_bills.daily_summary
WHERE TRY_CAST(date AS DATE)
      BETWEEN DATE '2007-04-01' AND DATE '2007-04-30'
ORDER BY consumption_date;
```

-----

## ğŸ’¡ Learnings

  - Building scalable batch pipelines with AWS serverless tools.
  - Applying ETL design best practices with Databricks and S3 partitioning.
  - Implementing rule-based anomaly detection using Lambda & SNS.
  - Exposing data insights via APIs and BI dashboards.

-----

## ğŸ§° Tools & Services

â€¢ AWS S3   
â€¢ Databricks    
â€¢ AWS Lambda    
â€¢ Amazon Athena    
â€¢ Amazon SNS    
â€¢ Amazon QuickSight    
â€¢ API Gateway    
â€¢ PySpark    
â€¢ Pandas    
â€¢ Boto3   

-----

## ğŸ Conclusion

This project demonstrates how to design a scalable, automated energy data processing system using AWS.

It transforms raw IoT-style meter readings into actionable insights â€” delivering bills, alerts, and analytics â€” all through a serverless, cost-optimized data architecture.

-----

## ğŸ‘¨â€ğŸ’» Author

**A. Yashwanth**

Aspiring Data Engineer | Python & AWS Enthusiast

ğŸ“§ www.linkedin.com/in/yashwantharavanti
